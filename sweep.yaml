program: main.py
command:
  - ${env}
  - ${interpreter}
  - -O
  - ${program}
  - ${args}
metric:
  name: population/mean_f1
  goal: maximize
method: random
parameters:
  criterion_key:
    value: 'bce'
  random_seed:
    value: 100 #[ 4168, 3773, 4181, 2945, 4132, 1405, 4328, 1720, 1691, 78 ]
  general_model_config:
    parameters:
      patch_size:
        value: 8
      dim:
        value: 256
      depth:
        value: 2
      heads:
        value: 5
      mlp_dim:
        value: 256
      dropout:
        value: 0.21
      emb_dropout:
        value: 0.1735
  pretrain:
    parameters:
      epochs:
        value: 50
      batch_size:
        value: 128
      lr:
        value: 0.00083
      train_fraction:
        value: 0.7
      do_pretraining:
        values: [ True, False ]
  finetune:
    parameters:
      n_frozen_layers:
        value: 0
      num_episodes:
        value: 10
      epochs:
        value: 70
      lr:
        value: 0.0002269
        # distribution: log_uniform_values
        # min: 0.00005
        # max: 0.0005
      batch_size:
        value: 64
      do_finetuning:
        values: [ True, False ]
  online:
    parameters:
      num_episodes:
        value: 30
        # min:
        #   1
        # max:
        #   15
      batch_size:
        # value: 10
        values: [ 3, 5, 10, 20 ]
      epochs:
        # value: 20
        values: [ 10, 20, 30 ]
      lr:
        # value: 0.0005
        distribution: log_uniform_values
        min: 0.00008
        max: 0.0007
      num_sessions:
        value: 3
      n_frozen_layers:
        values: [ 0, 1, 2 ]
      train_intervals:
        value: 1
      first_training_episode:
        value: 0
      additional_train_episodes:
        value: 30
      adaptive_training:
        value: False
      balance_classes:
        value: False
      buffer_size:
        values: [ 2_000, 3_000, 4_000 ]
      shuffle_episodes:
        value: False
