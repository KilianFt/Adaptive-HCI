program: main.py
command:
  - ${env}
  - ${interpreter}
  - -O
  - ${program}
  - ${args}
metric:
  name: population/mean_f1
  goal: maximize
method: random
parameters:
  criterion_key:
    value: 'bce'
  general_model_config:
    parameters:
      patch_size:
        value: 8
      dim:
        values: [ 256, 512, 1024 ]
      depth:
        values: [ 2, 3, 4 ]
      heads:
        values: [ 4, 5, 6 ]
      mlp_dim:
        values: [ 128, 256, 512, 1024 ]
      dropout:
        min: 0.1
        max: 0.25
      emb_dropout:
        min: 0.1
        max: 0.3
  pretrain:
    parameters:
      epochs:
        values: [ 40, 50, 60 ]
      batch_size:
        values: [ 128, 256 ]
      lr:
        distribution: log_uniform_values
        min: 0.0001
        max: 0.001
      train_fraction:
        value: 0.7
      # do_pretraining:
      #   values: [ True, False ]
  finetune:
    parameters:
      n_frozen_layers:
        value: 0
      num_episodes:
        value: 10
      epochs:
        values: [ 50, 70 ]
      lr:
        # value: 0.0005
        distribution: log_uniform_values
        min: 0.00005
        max: 0.0005
      batch_size:
        values: [ 64, 128 ]
      # do_finetuning:
        # values: [ True, False ]
  online:
    parameters:
      num_episodes:
        value: 30
        # values: [ 0, 30 ]
      batch_size:
        value: 32
      epochs:
        value: 20
      lr:
        # value: 0.0002
        distribution: log_uniform_values
        min: 0.00005
        max: 0.0006
      num_sessions:
        value: 3
      n_frozen_layers:
        value: 0
      train_intervals:
        value: 1
      first_training_episode:
        value: 0
      additional_train_episodes:
        value: 30
      adaptive_training:
        value: False
      balance_classes:
        value: False
      buffer_size:
        value: 3_000
